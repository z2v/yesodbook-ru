\chapter{Полнотекстовый поиск с использованием Sphinx}\label{chap:sphinx}
\footnotehref{http://sphinxsearch.com/}{Sphinx}~--- это сервер полнотекстового поиска, благодаря которому реализован поиск на многих сайтах. Код, необходимый для интеграции Sphinx и Yesod довольно краток, но, в то же время, он затрагивает несколько непростых моментов, а потому является прекрасной иллюстрацией того, как использовать некоторые детали внутреннего устройства Yesod.

По существу нам предстоит реализовать три вещи:
\begin{itemize}
  \item Сохранение данных, по которым мы хотели бы вести поиск. Для этого используется довольно незатейливый код Persistent, и мы не будем подробно останавливаться на этом моменте.
  \item Доступ из Yesod к результатам поиска Sphinx. На самом деле, благодаря пакету \footnotehref{http://hackage.haskell.org/package/sphinx}{sphinx}, это довольно просто.
  \item Предоставление содержимого документов серверу Sphinx. Вот где происходят интересные вещи! Вы узнаете, как напрямую передавать контент из базы данных напрямую в XML, который затем передаётся клиенту.
\end{itemize}

Полный код примера можно посмотреть в~\footnotehref{https://www.fpcomplete.com/user/snoyberg/yesod/case-study-sphinx}{FP Haskell Center}.

\section{Установка Sphinx}
В отличие от большинства других примеров, здесь для начала нам потребуется настроить и запустить сервер Sphinx. Я не собираюсь затрагивать все особенности Sphinx, отчасти, потому что они не относятся к делу, но в основном~--- потому что я далеко не эксперт в Sphinx.

Sphinx предоставляет три основных программы. Демон~\lstinline!searchd! непосредственно принимает запросы от клиента (в данном случае~--- нашего веб-приложения) и возвращает результат поиска. Программа~\lstinline!indexer! обрабатывает документы и создаёт индекс поиска. Утилита~\lstinline!search! предназначена для отладки, она посылает простые поисковые запросы серверу Sphinx.

Настройки Sphinx содержат два важных параметра~--- источник (source) и индекс~(index). Параметр source указывает Sphinx, откуда следует считывать информацию о документах. Поддерживается как прямое чтение из MySQL и PostgreSQL, так и использование XML-формата, известного как xmlpipe2. Им мы и воспользуемся. Это не только даст гибкость в плане выбора Persistent-бэкендов, но и продемонстрирует некоторые мощные концепции Yesod.

Второй важный параметр~--- это index. Sphinx может поддерживать несколько индексов одновременно, что позволяет организовать поиск для нескольких служб с помощью одного сервера. Каждому параметру index соответствует параметр source, определяющий, откуда брать данные.

Наше приложение будет предоставлять специальный URL (/search/xmlpipe) для генерации XML-файла для Sphinx, который и будет передаваться в indexer. В конфигурационный файл Sphinx следует прописать следующее:
\begin{lstlisting}[language=]
source searcher_src
{
    type = xmlpipe2
    xmlpipe_command = curl http://localhost:3000/search/xmlpipe
}

index searcher
{
    source = searcher_src
    path = /var/data/searcher
    docinfo = extern
    charset_type = utf-8
}

searchd
{
    listen   = 9312
    pid_file = /var/run/sphinxsearch/searchd.pid
}
\end{lstlisting}

Чтобы построить индекс, необходимо запустить \lstinline!indexer searcher!. Очевидно, это не будет работать, пока мы не запустим наше приложение. В рабочей версии сайта, эту команду следует запускать периодически с помощью crontab, чтобы индекс регулярно обновлялся.

\section{Базовая настройка Yesod}
Создадим новое Yesod-приложение. Нам понадобится одна таблица в базе данных для хранения документов, которые будут состоять из заголовка и текста. Эту таблицу мы будем хранить в SQLite. Создадим маршруты для поиска, добавления и просмотра документов, а также для генерации xmlpipe-файла для Sphinx.
\begin{lstlisting}
share [mkPersist sqlSettings, mkMigrate "migrateAll"] [persistLowerCase|
Doc
    title Text
    content Textarea
|]

data Searcher = Searcher
    { connPool :: ConnectionPool
    }

mkYesod "Searcher" [parseRoutes|
/ HomeR GET
/doc/#DocId DocR GET
/add-doc AddDocR POST
/search SearchR GET
/search/xmlpipe XmlpipeR GET
|]

instance Yesod Searcher

instance YesodPersist Searcher where
    type YesodPersistBackend Searcher = SqlPersistT

    runDB action = do
        Searcher pool <- getYesod
        runSqlPool action pool

instance YesodPersistRunner Searcher where -- see below
    getDBRunner = defaultGetDBRunner connPool

instance RenderMessage Searcher FormMessage where
    renderMessage _ _ = defaultFormMessage
\end{lstlisting}

Надеюсь, всё это должно быть уже знакомым на данный момент. Новое только одно~--- определение экземпляра класса типов~\lstinline'YesodPersistRunner'. Этот тип классов необходим для создания потоковых ответов от базы данных. Реализация по умолчания (\lstinline'defaultGetDBRunner') подходит почти всегда.

Далее мы определим две формы~--- одну для создания документа и одну для поиска:
\begin{lstlisting}
addDocForm :: Html -> MForm Handler (FormResult Doc, Widget)
addDocForm = renderTable $ Doc
    <$> areq textField "Title" Nothing
    <*> areq textareaField "Contents" Nothing

searchForm :: Html -> MForm Handler (FormResult Text, Widget)
searchForm = renderDivs $ areq (searchField True) "Query" Nothing
\end{lstlisting}%$

Передача параметра~\lstinline'True' в функцию~\lstinline'searchField' обеспечивает автоматическую установку фокуса на поле ввода при загрузке страницы. Наконец, объявляем обработчики для главной страницы (на ней отображаются формы добавления и поиска документов), а также для отображения и добавления документа:
\begin{lstlisting}
getHomeR :: Handler Html
getHomeR = do
    docCount <- runDB $ count ([] :: [Filter Doc])
    ((_, docWidget), _) <- runFormPost addDocForm
    ((_, searchWidget), _) <- runFormGet searchForm
    let docs = if docCount == 1
                then "There is currently 1 document."
                else "There are currently " ++ show docCount ++ " documents."
    defaultLayout
        [whamlet|
            <p>Welcome to the search application. #{docs}
            <form method=post action=@{AddDocR}>
                <table>
                    ^{docWidget}
                    <tr>
                        <td colspan=3>
                            <input type=submit value="Add document">
            <form method=get action=@{SearchR}>
                ^{searchWidget}
                <input type=submit value=Search>
        |]

postAddDocR :: Handler Html
postAddDocR = do
    ((res, docWidget), _) <- runFormPost addDocForm
    case res of
        FormSuccess doc -> do
            docid <- runDB $ insert doc
            setMessage "Document added"
            redirect $ DocR docid
        _ -> defaultLayout
            [whamlet|
                <form method=post action=@{AddDocR}>
                    <table>
                        ^{docWidget}
                        <tr>
                            <td colspan=3>
                                <input type=submit value="Add document">
            |]

getDocR :: DocId -> Handler Html
getDocR docid = do
    doc <- runDB $ get404 docid
    defaultLayout
        [whamlet|
            <h1>#{docTitle doc}
            <div .content>#{docContent doc}
        |]
\end{lstlisting}%$

\section{Поиск}
Теперь, когда мы разобрались со всей рутиной, займёмся непосредственно поиском. Нам понадобятся три вещи для отображения результатов поиска: идентификатор документа, к которому относится конкретная строка, заголовок этого документа, а также выдержка. Выдержки представляют собой выделенные участки документа, содержащие поисковый запрос~(рис.~\ref{Fig:search_results}).

\begin{figure}[hbt]
    \begin{center}
        \includegraphics[width=\textwidth]{21-search-results.png}
        \caption{Результат поиска}\label{Fig:search_results}
    \end{center}
\end{figure}

Давайте начнём с определения типа данных \lstinline'Result':
\begin{lstlisting}
data Result = Result
    { resultId      :: DocId
    , resultTitle   :: Text
    , resultExcerpt :: Html
    }
\end{lstlisting}

Теперь взглянем на обработчик запроса поиска: % не поисковый запрос, ибо так переводится search term
\begin{lstlisting}
getSearchR :: Handler Html
getSearchR = do
    ((formRes, searchWidget), _) <- runFormGet searchForm
    searchResults <-
        case formRes of
            FormSuccess qstring -> getResults qstring
            _ -> return []
    defaultLayout $ do
        toWidget
            [lucius|
                .excerpt {
                    color: green; font-style: italic
                }
                .match {
                    background-color: yellow;
                }
            |]
        [whamlet|
            <form method=get action=@{SearchR}>
                ^{searchWidget}
                <input type=submit value=Search>
            $if not $ null searchResults
                <h1>Results
                $forall result <- searchResults
                    <div .result>
                        <a href=@{DocR $ resultId result}>#{resultTitle result}
                        <div .excerpt>#{resultExcerpt result}
        |]
\end{lstlisting}%$

Ничего волшебного здесь не происходит: мы просто полагаемся на~\lstinline'searchForm', объявленную выше, и ещё необъявленную~\lstinline'getResults'. Эта функция просто принимает строку с поисковым запросом и возвращает список результатов. Здесь мы впервые взаимодействуем с API сервера Sphinx. Мы будем использовать две функции:~\lstinline'query' будет возвращать список совпадений, а \lstinline'buildExcerpts'~--- выделенные отрывки. Сначала разберём функцию~\lstinline!getResults!:
\begin{lstlisting}
getResults :: Text -> Handler [Result]
getResults qstring = do
    sphinxRes' <- liftIO $ S.query config "searcher" $ T.unpack qstring
    case sphinxRes' of
        ST.Ok sphinxRes -> do
            let docids = map (Key . PersistInt64 . ST.documentId) $ ST.matches sphinxRes
            fmap catMaybes $ runDB $ forM docids $ \docid -> do
                mdoc <- get docid
                case mdoc of
                    Nothing -> return Nothing
                    Just doc -> liftIO $ Just <$> getResult docid doc qstring
        _ -> error $ show sphinxRes'
  where
    config = S.defaultConfig
        { S.port = 9312
        , S.mode = ST.Any
        }
\end{lstlisting}%$

Функция~\lstinline'query' принимает три аргумента: параметры конфигурации, строку с именем индекса, по которому будет производиться поиск (<<searcher>> в нашем случае), и поисковый запрос. Функция возвращает список идентификаторов документов, содержащих искомую строку. Здесь есть небольшая хитрость, связанная с тем, что возвращаемые идентификаторы имеют тип~\lstinline'Int64', в то время как нам нужен~\lstinline'DocId'. Благодаря тому, что SQL-бэкенды \lstinline'Persistent' используют конструктор~\lstinline'PersistInt64' для идентификаторов, мы сможем получить требуемые значения, просто обернув их соответствующим образом.

\begin{remark}
Если вы работаете с бэкендом, использующим нечисловые идентификаторы, например MongoDB, вам придётся разработать какой-нибудь более изощрённый способ.
\end{remark}

Затем мы проходим в цикле по этим идентификаторам, получая список~\lstinline'[Maybe Result]', и используем функцию~\lstinline'catMaybes' для преобразования этого списка в~\lstinline'[Result]'. В where-клозе мы определяем локальные настройки, которые замещают номер порта, используемый по умолчанию, а также задают режим поиска, в котором возвращаются все документы, содержащие \emph{любое} слово из поискового запроса.

Наконец, взглянем на функцию~\lstinline'getResult':
\begin{lstlisting}
getResult :: DocId -> Doc -> Text -> IO Result
getResult docid doc qstring = do
    excerpt' <- S.buildExcerpts
        excerptConfig
        [T.unpack $ escape $ docContent doc]
        "searcher"
        (T.unpack qstring)
    let excerpt =
            case excerpt' of
                ST.Ok bss -> preEscapedToHtml $ decodeUtf8 $ mconcat bss
                _ -> ""
    return Result
        { resultId = docid
        , resultTitle = docTitle doc
        , resultExcerpt = excerpt
        }
  where
    excerptConfig = E.altConfig { E.port = 9312 }

escape :: Textarea -> Text
escape =
    T.concatMap escapeChar . unTextarea
  where
    escapeChar '<' = "&lt;"
    escapeChar '>' = "&gt;"
    escapeChar '&' = "&amp;"
    escapeChar c   = T.singleton c
\end{lstlisting}

Функция~\lstinline'buildExcerpts' принимает четыре аргумента: параметры конфигурации, содержимое документа, строку с именем индекса и поисковый запрос. Обратите внимание на экранирование специальных символов в документе. Sphinx его не производит, поэтому нам приходится заниматься этим самим.

Результат поиска, который мы получаем от Sphinx, представляет собой список элементов типа~\lstinline'Text'. Но мы, само собой разумеется, предпочли бы получить~\lstinline'Html'. Поэтому мы конкатенируем элементы списка в одну строку~\lstinline'Text' и затем используем функцию~\lstinline'preEscapedToHtml' для того, чтобы тэги, используемые для выделения найденных совпадений, не экранировались. Вот пример полученного в итоге HTML-кода:
\begin{lstlisting}[language=HTML]
&#8230; Departments.  The President shall have <span class='match'>Power</span> to fill up all Vacancies
&#8230;  people. Amendment 11 The Judicial <span class='match'>power</span> of the United States shall
&#8230; jurisdiction. 2. Congress shall have <span class='match'>power</span> to enforce this article by
&#8230; 5. The Congress shall have <span class='match'>power</span> to enforce, by appropriate legislation
&#8230;
\end{lstlisting}

\section{Генерируем xmlpipe}
Самое интересное мы приберегли напоследок. Для большинства обработчиков в Yesod рекомендуемый подход заключается в загрузке данных из базы в оперативную память и генерации вывода, основанного на этих данных. Так проще, но намного важнее то, что такой подход более устойчив к ошибкам. Если возникнет проблема во время загрузки данных из базы, пользователь получит должный код ответа 500.

\begin{remark}
Что я имею ввиду, говоря <<должный код ответа 500>>? Если вы начнёте передавать поток данных клиенту и в середине процесса наткнётесь на исключение, у вас не будет возможности изменить код ответа. Пользователь получит ответ с кодом 200, просто передача данных прервётся посередине. Помимо того, что частично сгенерированная страница сама по себе сбивает с толку, такое поведение ещё и не соответствует спецификации протокола HTTP.
\end{remark}

Генерация xmlpipe-вывода является прекрасным примером, где следует использовать альтернативный подход. У нас может быть огромное количество документов, а документы могут иметь размер порядка нескольких сотен килобайт. Если мы не воспользуемся поточным подходом, это может привести к большому времени ответа и использованию большого объёма оперативной памяти.

Так каким именно образом мы можем генерировать ответ в виде потока? Yesod предоставляет вспомогательную функцию на этот случай: \lstinline'ResponseSourceDB'. Эта функция принимает два аргумента: тип содержимого и кондуит~\lstinline'Source', генерирующий поток~\lstinline'Builder'ов. Yesod берёт на себя всю рутину: получение соединения с БД из пула, запуск транзакции и организации потока данных к пользователю.

Теперь нам известно, что из неких XML-данных требуется создать поток~\lstinline!Builder!'ов. К счастью, пакет \footnotehref{http://hackage.haskell.org/package/xml-conduit}{\lstinline'xml-conduit'} предоставляет интерфейс непосредственно для этого. Вообще, пакет \texttt{xml-conduit} предоставляет высокоуровневый интерфейс для работы с документами целиком, однако в нашем случае понадобится низкоуровневый интерфейс~\lstinline'Event', дабы обеспечить минимальное использование памяти. Вот функция, которая нам нужна:
\begin{lstlisting}
renderBuilder :: Monad m => RenderSettings -> Conduit Event m Builder
\end{lstlisting}

В переводе на русский язык это означает, что \lstinline'renderBuilder' принимает некие настройки (мы воспользуемся настройками по умолчанию) и преобразует поток~\lstinline!Event!'ов в поток~\lstinline!Builder!'ов. Выглядит неплохо. Всё, что нам теперь нужно~--- это поток~\lstinline!Event!'ов.

Кстати говоря, а как должен выглядеть наш XML-документ? Он довольно прост, имеется родительский элемент~\lstinline'sphinx:docset', элемент~\lstinline'sphinx:schema', содержащий одиночный элемент~\lstinline'sphinx:field' (который определяет элемент с содержимым документа), а затем по одному элементу~\lstinline'sphinx:document' для каждого документа в базе данных. Эти элементы будут содержать атрибут~\lstinline'id' и дочерний элемент~\lstinline'content'. Вот пример такого документа:
\begin{lstlisting}[language=XML,caption=Пример xmlpipe-документа]
<sphinx:docset xmlns:sphinx="http://sphinxsearch.com/">
    <sphinx:schema>
        <sphinx:field name="content"/>
    </sphinx:schema>
    <sphinx:document id="1">
        <content>bar</content>
    </sphinx:document>
    <sphinx:document id="2">
        <content>foo bar baz</content>
    </sphinx:document>
</sphinx:docset>
\end{lstlisting}

Каждый XML-документ будет начинаться с одинаковых событий (начать docset, начать schema и т.д.) и заканчиваться одним и тем же событием (закончить docset). Вот соответствующий код:
\begin{lstlisting}
toName :: Text -> X.Name
toName x = X.Name x (Just "http://sphinxsearch.com/") (Just "sphinx")

docset, schema, field, document, content :: X.Name
docset = toName "docset"
schema = toName "schema"
field = toName "field"
document = toName "document"
content = "content" -- no prefix

startEvents, endEvents :: [X.Event]
startEvents =
    [ X.EventBeginDocument
    , X.EventBeginElement docset []
    , X.EventBeginElement schema []
    , X.EventBeginElement field [("name", [X.ContentText "content"])]
    , X.EventEndElement field
    , X.EventEndElement schema
    ]

endEvents =
    [ X.EventEndElement docset
    ]
\end{lstlisting}

Теперь, когда у нас есть оболочка нашего документа, нам нужно получить~\lstinline!Event! для каждого конкретного документа. Это можно сделать при помощи довольно простой функции:
\begin{lstlisting}
entityToEvents :: (Entity Doc) -> [X.Event]
entityToEvents (Entity docid doc) =
    [ X.EventBeginElement document [("id", [X.ContentText $ toPathPiece docid])]
    , X.EventBeginElement content []
    , X.EventContent $ X.ContentText $ unTextarea $ docContent doc
    , X.EventEndElement content
    , X.EventEndElement document
    ]
\end{lstlisting}

Мы открываем элемент~\lstinline'document' с атрибутом~\lstinline'id', затем открываем элемент~\lstinline'content', вставляем содержимое документа, после чего закрываем оба элемента. Для преобразования~\lstinline!DocId! в значение типа~\lstinline!Text! мы используем функцию~\lstinline!toPathPiece!. Теперь нам нужно как-то преобразовать поток сущностей в поток событий. Для этого воспользуемся функцией~\lstinline!concatMap! из модуля~\lstinline!Data.Conduit.List!: \lstinline`CL.concatMap entityToEvents`.

Но чего мы \emph{действительно} хотим, так это создать поток этих событий непосредственно из базы данных. На протяжении большей части книги, мы использовали функцию~\lstinline!selectList!, однако Persistent также предоставляет (более мощную) функцию~\lstinline!selectSource!. С её помощью мы получаем в итоге следующую функцию:
\begin{lstlisting}
docSource :: Source (YesodDB Searcher) X.Event
docSource = selectSource [] [] $= CL.concatMap entityToEvents
\end{lstlisting}%$

Оператор~\lstinline'$=' соединяет источник с каналом, возвращая новый источник. Теперь, когда у нас есть источник~\lstinline!Event!'ов, всё, что нам нужно~--- это окружить его событиями начала и конца документа. Благодаря тому, что Source является экземпляром класса~\lstinline!Monad!, это проще простого:
\begin{lstlisting}
fullDocSource :: Source (YesodDB Searcher) X.Event
fullDocSource = do
    mapM_ yield startEvents
    docSource
    mapM_ yield endEvents
\end{lstlisting}

Мы почти закончили, осталось только применить всё это в функции~\lstinline!getXmlpipeR!. Для этого мы воспользуемся функцией~\lstinline'respondSourceDB', упомянутой выше. Последняя необходимая уловка~--- преобразовать поток~\lstinline'Event'ов в поток~\lstinline'Chunk Builder'. Преобразование в поток~\lstinline'Builder' выполняется функцией~\lstinline'renderBuilder', после чего каждый~\lstinline'Builder' оборачивается в отдельный~\lstinline'Chunk':
\begin{lstlisting}
getXmlpipeR :: Handler TypedContent
getXmlpipeR =
    respondSourceDB "text/xml"
 $  fullDocSource
 $= renderBuilder def
 $= CL.map Chunk
\end{lstlisting}

\section{Полный код примера}

\includecode{21/source.hs}
