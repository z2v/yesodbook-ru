\chapter{Кондуиты}

Кондуиты используются для обработки потоков данных. Часто ленивые вычисления
позволяют обрабатывать большие объемы не загружая их в память целиком. Однако, 
использование такого подхода для ввода-вывода влечет требование ленивости ввода-вывода.
А его главный недостаток --- недетерминированность: у нас нет никаких гарантий когда
финализаторы наших ресурсов будут запущены. Для небольшого приложения это допустимо, но
для высоко нагруженного веб-сервера мы можем очень быстро исчерпать допустимые ресурсы,
например, дескрипторы для файлов.

Кондуиты позволяют оперировать большими потоками данных при детерминированном управлении
ресурсами. Они предоставляют унифицированный интерфес для потоков данных вне зависимости
от того откуда они поступают: из файлов, сокетов или памяти. В сочетании с ResourceT мы
можем безопасно работать с ресурсами, зная, что они будут гарантированно освобождены даже
в случае исключений.

В этом приложении рассматривается пакет conduit версии \verb=0.2=.


Кондуиты в двух словах

Хотя понимание низкоуровневой механики кондутов рекомендуется, вы можете далеко
продвинуться и без неё. Давайте начнем с нескольких высокоуровневых примеров. Не
беспокойтесь, если некоторые детали вам будут сейчас непонятны --- мы разберем всё в этом
приложении. Начнем с терминологии и нескольких примеров кода.

\begin{itemize}
 \item \textit{Источник(source)} генерирует данные. Они могут быть в файле, придти из
сокета или лежать списком в памяти. Мы обращаемся к этим данным забирая их из источника.
 \item Sink --- потребляет данные. Основные примеры будут о функции суммирования
(сложения чисел из потока), файловом канале (пишет все пришедшие байты в файл) или
сокете. В конце обработки данных возвращается какое-то значение.
% FIXME: как sink на русский переводить?
 \item \textit{Кондуиты} преобразуют данные. В простейшем примере это будет функция map,
хотя бывает много других. Мы добавляем данные в кондуит также как и в sink. Но вместо
возврата одного значения, кондуит может вернуть несколько результатов каждый раз, когда в
него добавляются данные.
  \item \textit{Комбинирование (fuse)} --- термин Давида Мазьереса. Кондуит можно 
скомбинировать с источником данных (с помощью оператора \verb=$==) и получить
модифицированный источник. Например, мы можем взять источник, читающий байты из файла, и
кондуит, который преобразует байты в текст. Скомбинировав их, мы получим получим
источник, читающий текст из файла. Аналогично, кондуит и sink можно скомбинировать в sink
(оператор \verb#=$#), а два кондуита --- в новый кондуит (оператор \verb#=$=#).
  \item Соединение. Мы можем присоединять источник к sink используя оператор \verb=$$=.
Это приведет к тому, что данные будут передаваться из источника в sink до тех пор, пока
источник или sink не сообщать, что они ``закончили''.
\end{itemize}

Рассмотрим несколько примеров кода.
\begin{lstlisting}
{-# LANGUAGE OverloadedStrings #-}
import Data.Conduit -- the core library
import qualified Data.Conduit.List as CL -- some list-like functions
import qualified Data.Conduit.Binary as CB -- bytes
import qualified Data.Conduit.Text as CT

import Data.ByteString (ByteString)
import Data.Text (Text)
import qualified Data.Text as T
import Control.Monad.ST (runST)
\end{lstlisting}
Начнем с основ: соединим источник с sink. Мы будем использовать встроенные файловые
функции для эффективности, константной памяти и ресурсо-безопасного копирования файлов.

Обратите внимание: вначале мы используем \verb=$$= для соединения источник с sink, а
затем используем rubResourceT.
\begin{lstlisting}
copyFile :: FilePath -> FilePath -> IO ()
copyFile src dest = runResourceT $ CB.sourceFile src $$ CB.sinkFile dest
\end{lstlisting}
Модуль Data.Conduit.List предоставляет некоторые число функций для создания sink,
источников и кондуитов. Вот так выглядит свёртка: суммирование чисел.
\begin{lstlisting}
sumSink :: Resource m => Sink Int m Int
sumSink = CL.fold (+) 0
\end{lstlisting}
Мы можем реализовать то же самое более низкоуровнево, используя функцию \verb=sinkState=.
Они принимает три параметра: начальное состояние, функцию приема дополнительных данных и
функцию закрытия.
\begin{lstlisting}
sumSink2 :: Resource m => Sink Int m Int
sumSink2 = sinkState
    0 -- начальное значение
    -- обновим состояния согласно полученным данным 
    -- и сообщим что необходимы дополнительные данные
    (\accum i -> return $ StateProcessing (accum + i))
    (\accum -> return accum) -- вернуть текущее значение при закрытии
\end{lstlisting}
Другая полезная функция --- \verb=sourceList=. Скомбинировав её с нашей функций
\verb=sumSink=, мы получим встроенную реализацию функции sum.
\begin{lstlisting}
sum' :: [Int] -> Int
sum' input = runST $ runResourceT $ CL.sourceList input $$ sumSink
\end{lstlisting}
Поскольку это Haskell давайте создадим источник, который генерирует все числа Фибоначчи.
Для этого мы будем использовать sourceState. Состояние будет содеражать следующие два
число в последовательности. Также нам понадобится функция, которая вернет следующее число
и обновит состояние.
\begin{lstlisting}fibs :: Resource m => Source m Int
fibs = sourceState
    (0, 1) -- initial state
    (\(x, y) -> return $ StateOpen (y, x + y) x)
\end{lstlisting}
Посчитаем сумму первых 10 чисел Фибоначчи. Мы можем использовать изолированный кондуит,
чтобы быть уверенными, что sink суммирования приняла только 10 значений.
\begin{lstlisting}sumTenFibs :: Int
sumTenFibs =
       runST -- runs fine in pure code
     $ runResourceT
     $ fibs
    $= CL.isolate 10 -- fuse the source and conduit into a source
    $$ sumSink
\end{lstlisting}
Мы также можем скомбинировать кондуит и sink, поменяв местами некоторые операторы.
\begin{lstlisting}sumTenFibs2 :: Int
sumTenFibs2 =
       runST
     $ runResourceT
     $ fibs
    $$ CL.isolate 10
    =$ sumSink
\end{lstlisting}
Отлично, а теперь сделаем несколько кондуитов. Давайте преобразовывать числа в текст.
Кажется, функция map нам подойдет...
\begin{lstlisting}
intToText :: Int -> Text -- дополнительная функция 
intToText = T.pack . show

textify :: Resource m => Conduit Int m Text
textify = CL.map intToText
\end{lstlisting}
Аоспользуемся функцией conduitState также как это было сделано выше. Здесь нам не нужно
состояние, поэтому подставим фиктивно значение.
\begin{lstlisting}textify2 :: Resource m => Conduit Int m Text
textify2 = conduitState
    ()
    (\() input -> return $ StateProducing () [intToText input])
    (\() -> return [])
\end{lstlisting}
Сделаем кондуит unlines, который будет добавлять перевод строки в конце каждого блока
входных данных. Воспользуемся функцией CL.map. feel free to write it with conduitState as
well for practice.
\begin{lstlisting}unlines' :: Resource m => Conduit Text m Text
unlines' = CL.map $ \t -> t `T.append` "\n"
\end{lstlisting}
А теперь напишем функцию, которая печатает первые N чисел фибоначчи. Используем
кодировку UTF8.
\begin{lstlisting}writeFibs :: Int -> FilePath -> IO ()
writeFibs count dest =
      runResourceT
    $ fibs
   $= CL.isolate count
   $= textify
   $= unlines'
   $= CT.encode CT.utf8
   $$ CB.sinkFile dest
\end{lstlisting}
Мы использовали оператор \verb#$=#, чтобы комбинировать кондуиты с источниками, получая
новые источники. Можно делать и обратное: комбинировать кондуиты и sink. Можно даже
скомбинировать два кондуита.
\begin{lstlisting}writeFibs2 :: Int -> FilePath -> IO ()
writeFibs2 count dest =
      runResourceT
    $ fibs
   $= CL.isolate count
   $= textify
   $$ unlines'
   =$ CT.encode CT.utf8
   =$ CB.sinkFile dest
\end{lstlisting}
Или мы можем скомбинировать все написанные кондуиты в один
\begin{lstlisting}someIntLines :: ResourceThrow m -- encoding can throw an exception
             => Int
             -> Conduit Int m ByteString
someIntLines count =
      CL.isolate count
  =$= textify
  =$= unlines'
  =$= CT.encode CT.utf8
\end{lstlisting}
Теперь используем кондуит
\begin{lstlisting}
writeFibs3 :: Int -> FilePath -> IO ()
writeFibs3 count dest =
      runResourceT
    $ fibs
   $= someIntLines count
   $$ CB.sinkFile dest

main :: IO ()
main = do
    putStrLn $ "First ten fibs: " ++ show sumTenFibs
    writeFibs 20 "fibs.txt"
    copyFile "fibs.txt" "fibs2.txt"
\end{lstlisting}

Структура главы.

Остаток этой главы освещает следующие темы.
\begin{itemize}
 \item ResourceT --- техника, которая позволяет управлять освобождением ресурсов.
 \item Источники --- наши генераторы данных
 \item Sinks --- потребители данных
 \item Кондуиты --- преобразователи данных
 \item Буферизация --- техника борьбы с инверсией управления.
\end{itemize}

Трансформер монады Resource

Трансформер монады Resource (ResourceT) играет существенную роль в управлении ресурсами в
проектах, использующих кондуиты. Он поставляется вместе с библиотекй \verb=conduit=. Мы
будем рассматривать ResourceT самого по себе. Хотя некоторые решения в его дизайне
основаны на кондуитах, ResourceT можно использовато самого по себе.

Назначение

Что не так с этим кодом?
\begin{lstlisting}
import System.IO

main = do
    output <- openFile "output.txt" WriteMode
    input  <- openFile "input.txt"  ReadMode
    hGetContents input <<= hPutStr output
    hClose input
    hClose output
\end{lstlisting}

Если файл input.txt отсутствует, бросится исключение при попытке его открыть. В
результате hClose output никогда не будет вызвано и мы получим утечку важного ресурса
(дескриптора файлов). В небольшой программе это не критично, но очевидно, что мы не
сможем себе этого позволить в высоко нагруженном процессе сервера с большим аптаймом

К счастью проблема решается довольно просто:
\begin{lstlisting}
import System.IO

main =
    withFile "output.txt" WriteMode $ \output ->
    withFile "input.txt" ReadMode $ \input ->
    hGetContents input <<= hPutStr output
\end{lstlisting}

Использование withFile гшарантирует, что дескриптор будет закрыт, даже в случае
исключений. Оно также поддерживает асинхронные исключения. Вообще говоря, это прекрасный
подход для случаев, когда вы можете его использовать. Хотя withFile просто использовать,
часто он влечет переписывание всей программы. А это переписывание может быть очень
скучным и сильно неэффективным.

Возьмем, например, енумераторы. Если вы заглянете в документацию, то найдете функцию
enumFile для чте ния содержимого файла, но не найдете функции iterFile для записи
содержимого в файл. Так сделано потому, что поток управления итератов не позволяет
правильно управлять дескрипторами. Взамен, чтобо записать в файл вам надо создавать
дескриптор до запуска итерата, т.е.: 

\begin{lstlisting}
import System.IO
import Data.Enumerator
import Data.Enumerator.Binary

main =
    withFile "output.txt" WriteMode $ \output ->
    run_ $ enumFile "input.txt" $$ iterHandle output
\end{lstlisting}

Этот код работает хорошо, но представьте, что вместо простой передачи данных в файл, нам
надо провести длительное вычисление перед использование дескриптора. Мы будем иметь
дескриптор задолго до того, как он нам понадобится, блокируя важный ресурс нашего
приложения. Кроме этого, часто мы не можем открыть файл, так как мы поймем какой файл
надо открывать только тогда, когда прочитаем все данные.

Одна из заявленных целей кондуитов --- решить эту пролему с помощью ResourceT. Программа
выше может быть переписана вот так:
\begin{lstlisting}
{-# LANGUAGE OverloadedStrings #-}
import Data.Conduit
import Data.Conduit.Binary

main = runResourceT $ sourceFile "input.txt" $$ sinkFile "output.txt"
\end{lstlisting}

Как это работает

There are essentially three base functions on ResourceT, and then a bunch of
conveniences thrown on top. The first function is:
\begin{lstlisting}
register :: IO () -> ResourceT IO ReleaseKey
\end{lstlisting}
Полииморфность этой функции и остальных ниже не используется в полную силу, на самом деле
они могут работать с другими монадами кроме IO. In fact, almost any transformer on top of
IO, as well as any ST stacks, work. Мы разъясним детали познее.
% FIXME: Я провтыкал что такое ST
Эта функция региструет кусок кода, утверждения которого будут выполнены. Она также
возвращает ReleaseKey, которое используется в следующей функции:
\begin{lstlisting}release :: ReleaseKey -> ResourceT IO ()
\end{lstlisting}
Возоы функции \verb=release= от ReleaseKey немедленно выполняет действии, которое ыло
зарегистрировано ранее. Мы можем вызывать \verb=release= от одной и той же ReleaseKey
стольк раз, сколько пожелаем, при первом вызове регистрация действия отменяется. Это
значит, что вы можете безопасно зарегистрировать действие освобождения памяти, не
заботясь о том, что оно будет выполнено дважды.

Со временем, мы можем захотеть освободить ресурс, ResourceT. Чтобы сделать это,
воспользуемся:
\begin{lstlisting}
runResourceT :: ResourceT IO a -> IO a
\end{lstlisting}
В этой внешене невинной функции происходит вся магия. 
 It runs through ("пронизывать") all of
the
registered cleanup actions and performs them. Она безопасна с точки зрения исключений, в
том смысле, что освобождения ресурсов будут выполнены в случае и синхронных, и
асинхронныъ исключений. И, как было упомянуто выше, вызов функции release отменит
регистрацию действия. Таким образом нам не стоит беспокоиться о повторном освобождении
ресурсов.

Наконец, для удобства, мы приведем ещё одну функцию для выделения ресурса и регистрации
действия по его освобождению:
\begin{lstlisting}
with :: IO a -- ^ allocate
     -> (a -> IO ()) -- ^ free resource
     -> ResourceT IO (ReleaseKey, a)
\end{lstlisting}

Теперь перепишем с использованием ResourceT первый некачественный пример:
\begin{lstlisting}
import System.IO
import Control.Monad.Trans.Resource
import Control.Monad.Trans.Class (lift)

main = runResourceT $ do
    (releaseO, output) <- with (openFile "output.txt" WriteMode) hClose
    (releaseI, input)  <- with (openFile "input.txt"  ReadMode)  hClose
    lift $ hGetContents input <<= hPutStr output
    release releaseI
    release releaseO
\end{lstlisting}

Сейчас мы можем не беспокоиться об исключениях, затрудняющих освобождение ресурсов. Мы
можем опустить вызовы \verb=release= в таких маленьких программах как эта, это ни на что
не повлияет. Но в больших приложениях, где мы продолжим обработку дальше, этот код
гарантирует, что дескрипторы ресурсов освободятся как только это станет возможным, снижая
потребление ресурсов до минимума.

Несколько слов о типах

Как было упомянуто, ResourceT это нечто большее, чем код, исполняемый надо IO. Но давайте
опустим некторые вещи, которые нам потребуются от этой монады.

Мутабельные ссылки, для хранения зарегистрированный действий по освобождению ресурсов.
Нам может показаться, что мы можем использовать StateT трансформер, но тогда наше
состояние не сможет корректно обходиться с исключениями.


We only want to register actions in the base monad. For example, if we have a
ResourceT (WriterT [Int] IO) stack, we only want to register
IO actions. This makes it easy to lift our stacks around (i.e., add an extra
transformer to the middle of an existing stack), and avoids confusing issues about the
threading
of other monadic side-effects.
Some way to guarantee an action is performed, even in the presence of exceptions. This
boils
down to needing a bracket-like function.

Для начала определим класс типов для монад, которые имеют мутабельные ссылки
\begin{lstlisting}
 class Monad m => HasRef m where
    type Ref m :: * -> *
    newRef' :: a -> m (Ref m a)
    readRef' :: Ref m a -> m a
    writeRef' :: Ref m a -> a -> m ()
    modifyRef' :: Ref m a -> (a -> (a, b)) -> m b
    mask :: ((forall a. m a -> m a) -> m b) -> m b
    mask_ :: m a -> m a
    try :: m a -> m (Either SomeException a)
\end{lstlisting}

We have an associated type to signify what the reference type should be. (For fans of
fundeps,
you'll see in the next section that this has to be an associated type.) Then we provide a
number of basic reference operations. В конце несколько функций для работы с
исключениями, которые необходимы для безопасной реализации функций, описанных в
последнем разделе. Реализация инстанса для IO допольно прямолинейна:
  
\begin{lstlisting}
instance HasRef IO where
    type Ref IO = I.IORef
    newRef' = I.newIORef
    modifyRef' = I.atomicModifyIORef
    readRef' = I.readIORef
    writeRef' = I.writeIORef
    mask = E.mask
    mask_ = E.mask_
    try = E.try 
\end{lstlisting}
Однако, при реализации инстанса монады ST мы сталкиваемся с проблемой: мы никак не можем
обрабатывать исключения в монаде ST. В результате, функции mask, mask\_ и try имеют
дефолтную реализацию без проверки исключений. Сейчас мы сформулируем первое
предупреждение:

\textit{Операции в монаде ST не безопасны относительно исключений. Мы не должен выделять
важные ресурсы в монаде ST когда используем ResourceT. You might be wondering why bother
with
ResourceT at all then for ST. The answer is that there is a
lot you can do with conduits without allocating scarce resources, and ST is a
great way to do this in a pure way. But more on this later. }

% FIXME: Что такое associated type?
Пункт номер 2: нам надо как-то работать с монадой Base. Опять же, мы можем
использовать 
associated type (почему опять --- будет сказано в следующем разделе). Наше решение будет
выгялдеть примерно так:
\begin{lstlisting}
class (HasRef (Base m), Monad m) => Resource m where
    type Base m :: * -> *

    resourceLiftBase :: Base m a -> m a 
\end{lstlisting}
Мы забыли о пункте 3 --- функции а-ля корзина. Нам понадобится ещё один метод в классе
типов:
\begin{lstlisting}
resourceBracket_ :: Base m a -> Base m b -> m c -> m c 
\end{lstlisting}
Причной, по которой перыве два аргумента функции resourceBracket\_ ``живут'' в монаде
Base,
является то, что в ResourceT все выделения и освобождения ресурсов, происходят в базовой
 монаде.

So on top of our HasRef instance for IO, we now need a
Resource instance as well. This is similarly straight-forward:
\begin{lstlisting}
 instance Resource IO where
    type Base IO = IO
    resourceLiftBase = id
    resourceBracket_ = E.bracket_
\end{lstlisting}

We have similar ST instances, with resourceBracket\_ having no
exception safety. The final step is dealing with monad transformers. We don't need to
provide a
HasRef instance, but we do need a Resource instance. The
tricky part is providing a valid implementation of resourceBracket\_. For this,
we use some functions from monad-control:

\begin{lstlisting}
instance (MonadTransControl t, Resource m, Monad (t m))
        => Resource (t m) where
    type Base (t m) = Base m

    resourceLiftBase = lift . resourceLiftBase
    resourceBracket_ a b c =
        control' \$ \run -> resourceBracket_ a b (run c)
      where
        control' f = liftWith f >>= restoreT . return 
\end{lstlisting}
For any transformer, its base is the base of its inner monad. Similarly, we lift to the
base by
lifting to the inner monad and then lifting to the base from there. The tricky part is the
implemetnation of \verb=resourceBracket_=. I will not go into a detailed explanation,
as I would simply make a fool of myself.

Определение ResourceT

Теперь у нас достаточно информации, чтобы осмыслить определение типа ResourceT:
\begin{lstlisting}
newtype ReleaseKey = ReleaseKey Int

type RefCount = Int
type NextKey = Int

data ReleaseMap base =
    ReleaseMap !NextKey !RefCount !(IntMap (base ()))

newtype ResourceT m a =
    ResourceT (Ref (Base m) (ReleaseMap (Base m)) -> m a)
\end{lstlisting}
Мы видим, что ReleaseKey это просто Int. Если вы загляните на несколько строк вниз, то
это определение обретет смысл, так как мы используем IntMap для того, чтобы хранить
зарегистрированые действия. Мы также определяем два синонима: RefCount и NextKey. NextKey
хранит последнее присвоенное значение ключа и инкрементируется каждый раз, когда
вызывается функция \verb=register=. Мы коснемся этого немного позже.

ReleaseMap хранит три вида информации: следующий ключ, счетчик ссылок, и затем map всех
зарегистрированных действий (actions). Заметьте, что ReleaseMap принимает типовый
параметр base, который определяет, какой монады действия по освобождению ресурсов  будут
использоваться 
% FIXME хрень какая-то. В оригинале which states which monad release actions must live
% in.

В конце концов, ResourceT является по существу ReaderT, который хранит мутабельную
ссылку на ReleaseMap. The reference type is determined by the base
of the monad in question, as is the cleanup monad. This is why we need to use associated
types.

Целью оставшейся части кода в модуле Control.Monad.Trans.Resource
является создание инстансов типа ResourceT.

Другие классы типов

Модуля предоставляет ещё три класса типов:
   
ResourceUnsafeIO

Любая монада может втянуть (lift) IO действия в себя, но это может быть небезопасно.
Первый пример этого --- ST. Care should be taken to
only lift actions which do not acquire scarce resources and which don't "fire the
missiles." Другими словами, все обычные предпреждения насчет unsafeIOToST имеют
справедлиы.
  
ResourceThrow

Для действий, которые могут бросить исключение.  Это автоматически приминимо ко всем
монадам на базе IO. Для ST-монад вы можете использовать трансформер ExceptionT, чтобы
предоставить возможности пробрасывания исключений. Это потребуется для некоторых функций
кондуитов, например, декодирование текста.
   
ResourceIO

Включает в себя несколько тайпклассов, в том числе два
упомянутых выше. Он создан только для удобства, мы может получить тот же результат без
него, потребуется только внимательнее оперировать типами (you'd just have to do a lot
more typing).
   
Forking

Может показаться, что ответвление от процесса хронически небезопасно при использовании 
ResourceT, так как родительский поток процесс может вызвать \verb=runResourceT= в то время
как дочерний использует ресурсы. Это, конечно же, так, если вы используете обычную
функцию forkIO.

Вообще говоря, вы не можете использовать стандартный forkIO, так как он использует монаду
IO, но вы можете использовать функцию fork из залифченой базовой монады.
По этой причине пакет regions не предоставляет экземпляр MonadBaseControl для этого
трансформатора (который очень похож на ResourceT). Однако, назначение ResourceT
не запретить программистам стрелять себе в ногу, а только, чтобы было легче писать
правильно. Поэтому, мы всё же предостовляем экземпляр, даже если он может быть
использован неправильно. Чтобы решить эту проблему ResourceT включает в себя
счетчик ссылок. Когда вы образовываете новый поток с помощью resourceForkIO,
значение RefCount в ReleaseMap инкрементируется. Всякий раз, когда runResourceT
вызывается, это значение декрементируется. Только когда оно достигент нуля происходят
действия по освобождению ресурсов.
 
Дополнительные функции для удобства

В дополнение мы расскажем про несколько функций, созданных для удобства.
%   
Функции \verb=newRef=, \verb=writeRef=, и \verb=readRef= оборачивают
функции с HasRef, позволяют им работать с любым ResourceT.
\verb=withIO= по сути является функцией \verb=with= с ограниченным типом, но она 
позволяет работать с некоторой вложенностью типов, в то время как при \verb=with=
пришлось бы продираться в глубину (but working around 
some of the nastiness with types you would otherwise run into). В общем, вам стоит
использовать withIO для написания IO кода.
\verb=transResourceT= позволит вам модифицировать в какой монаде исполняется ваш
\verb=ResourceT=, assuming it keeps the same
\begin{lstlisting}
    base.transResourceT :: (Base m ~ Base n)
               => (m a -> n a)
               -> ResourceT m a
               -> ResourceT n a
transResourceT f (ResourceT mx) = ResourceT (\r -> f (mx r))
\end{lstlisting}  

Источники

Проще всего понять что это такое посмотрев  на типы:
\begin{lstlisting}
data SourceResult m a = Open (Source m a) a | Closed
data Source m a = Source
    { sourcePull :: ResourceT m (SourceResult m a)
    , sourceClose :: ResourceT m ()
    }
\end{lstlisting}
Источник имеет две операции: вы можете запросить ещё данных и вы можете закрыть его (как,
например, закрыть дескриптор файла). При запросе новых данных вы или получаете немного
данных и новое  значение типа Source (источник остается открытым), или Nothing (источник
закрывается) . Давайте посмотрим на простеёшие примеры.
\begin{lstlisting}
  -- START
import Prelude hiding (repeat)
import Data.Conduit

-- | Never give any data
eof :: Monad m => Source m a
eof = Source
    { sourcePull = return Closed
    , sourceClose = return ()
    }

-- | Always give the same value
repeat :: Monad m => a -> Source m a
repeat a = Source
    { sourcePull = return $ Open (repeat a) a
    , sourceClose = return ()
    }
-- STOP
main :: IO ()
main = return ()
\end{lstlisting}
Эти источники довольно прямолинейны, так как они всегда возвращают одно и то же. К тому
же их функции закрытия ничего не делают. Вам может показаться, что это баг: не должны ли 
мы возвращать в sourcePull \verb=return Closed= после того, как источник был закрыт? Это
не является необходимым, since one of the rules of sources is
that they can never be
reused. Другими словами:

    
\textit{Если источник вернул Open, то он предоставил вам новый источник, с которым и
стоит работать, заменив оригинальный. Если источник вернул Closed, тогда, вы больше не
может выполнять операции над ним.}
    
Не стоит очень беспокоиться по поводу сохранения этого инварианта. На практике, вам почти
не придется вызывать sourcePull или sourceClose самостоятельно. Также, навряд ли вам
придутся их самостоятельно описывать (для этого существуют sourceState и sourceIO).
%In fact, you hardly  even write them yourself either (that's what sourceState and
% sourceIO are for). FIXME уточнить это предожение
Идея в том, что мы можем сделать некоторые предположения, когда реализовываем источники. 
 

Состояние

В двух примерах источников выше есть кое-что общее: они всегда возвращают то же самое
значение. Другими словами, у них не состояния. Для более-менее серьёзных источников надо
потреуется реализовывать состояние.

Состояние может запросто быть определено вне нашей программы. Например, если мы
реализовываем источник, который читает данных из дескриптора, нам не нужно вручную
указывать никакого состояния, потому что дескриптор имеет состояние сам по себе.
Будем хранить состояние в источнике путём обновления возвращаемого значения типа Source в
конструкторе Open. Лучше всего это рассмотреть на примере.

\begin{lstlisting}
-- START
import Data.Conduit
import Control.Monad.Trans.Resource

-- | Provide data from the list, one element at a time.
sourceList :: Resource m => [a] -> Source m a
sourceList list = Source
    { sourcePull =
        case list of
            [] -> return Closed -- no more data

            -- This is where we store our state: by return a new
            -- Source with the rest of the list
            x:xs -> return $ Open (sourceList xs) x
        , sourceClose = return ()
        }
-- STOP
main :: IO ()
main = return ()
\end{lstlisting}

Всякий раз, когда мы забираем данные из источника, он проверяет список. Если он пуст,
возвращаем Closed, что разумно. Если не пуст, возвращаем Open со следующим значением
списка и новым значением источника, вызванного от хвоста списка.

sourceState and sourceIO

В добавление к возможности манипулировать источниками, мы также имеет несколько функций,
позволяющих создавать источники более высокоуровнево. sourceState позволяет писать
код как будто вы используете монаду State. Вы предоставляете начальное состояние,
вункцию получения данных от текущего состояния, а она возвращает новое состояние и
новое значение. Перепишем sourceList с помощью неё:

\begin{lstlisting}
  -- START
import Data.Conduit
import Control.Monad.Trans.Resource

-- | Provide data from the list, one element at a time.
sourceList :: Resource m => [a] -> Source m a
sourceList state0 = sourceState
    state0
    pull
  where
    pull [] = return StateClosed
    pull (x:xs) = return $ StateOpen xs x
-- STOP
main :: IO ()
main = return ()
\end{lstlisting}

Замечание по использованию конструкторов StateClosed и StateOpen. Они очень похожи на
Closed и Open, за исключением того, что при указании следующего источника вы указываете и
следующее состояние (остаток списка).

Другое распространенное применение --- аллокация ресурсов ввода-вывода (например,
открытие файла), регистрация функции свобождения ресурса (закрытие файла) и
предоставление функции получения данных из ресура.
В пакете conduit присутствует встроенная функция \verb=sourceFile=, которая выдает поток
значений типа ByteString. Давайте напишем совершенно неэффективную альтернативу,
которая будет возвразать поток символов.

\begin{lstlisting}
-- START
import Data.Conduit
import Control.Monad.Trans.Resource
import System.IO
import Control.Monad.IO.Class (liftIO)

sourceFile :: ResourceIO m => FilePath -> Source m Char
sourceFile fp = sourceIO
    (openFile fp ReadMode)
    hClose
    (\h -> liftIO $ do
        eof <- hIsEOF h
        if eof
            then return IOClosed
            else fmap IOOpen $ hGetChar h)
-- STOP
main :: IO ()
main = return ()
\end{lstlisting}

Как и \verb=sourceState=, она использует конструкторы \verb*|Open| и \verb*|Closed|.
Функция sourceIO выполняет несколько действий  для нас:
\begin{itemize}
 \item Регистрирует функцию освобождения ресурса, с трансформерос ResourceT,
гарантируя, что она будет вызвана даже в случае исключений.
 \item Инициализирует поле sourceClose чтобы освободить ресурс немедленно.
 \item Как только вернется IOClosed, будет вызвано освобождение русурса.
\end{itemize}
  
Sinks

Они поглощают потоки данных и генерируют результат. Они должны всегда выдавать результат
и толтко единичный результат. Это зафиксированно в их типе.

Экземпляр Monad для sink упрощает композицию нескольких sink, в больший sink. Вы также
можете использовать встроенные функции для большинства своих нужд. Как и с источниками,
вам редко понадобиться погружаться в тонкости реалллизации. Начнем с примера:
получение строк и потока символов (будет предполагать наличие перевод строк в стиле Unix,
для простоты).

\begin{lstlisting}
import Data.Conduit
import qualified Data.Conduit.List as CL

-- Get a single line from the stream.
sinkLine :: Resource m => Sink Char m String
sinkLine = sinkState
    id -- initial state, nothing at the beginning of the line
    push
    close
  where
    -- On a new line, return the contents up until here
    push front '\n' =
        return $ StateDone Nothing $ front []

    -- Just another character, add it to the front and keep going
    push front char =
        return $ StateProcessing $ front . (char:)

    -- Got an EOF before hitting a newline, just give what we have so far
    close front = return $ front []

-- Get all the lines from the stream, until we hit a blank line or EOF.
sinkLines :: Resource m => Sink Char m [String]
sinkLines = do
    line <- sinkLine
    if null line
        then return []
        else do
            lines <- sinkLines
            return $ line : lines

content :: String
content = unlines
    [ "This is the first line."
    , "Here's the second."
    , ""
    , "After the blank."
    ]

main :: IO ()
main = do
    lines <- runResourceT $ CL.sourceList content $$ sinkLines
    mapM_ putStrLn lines
\end{lstlisting}
Running this sample produces the expected output:
\begin{verbatim}
This is the first line.
Here's the second.
\end{verbatim}
 
 
Функция sinkLine демонстрирует использование sinkState, которая очень похожа только что
виденную функцию sourceState. Она принимает три параметра: начальное состояние,
функцию ``добавления`` \verb=push= 
(принимает текущее состояние и входные данные и возвращает новое состояние и результат)
и функцию закрытия (принимает текущее состояние и возвращает вывод). Как
противоположность к sourceState, которая не нуждается в функции закрытия, sink должна
всегда возвращать результат.

В нашей функции push две клаузы. Когда она получет символ конца строки, процесс
заканчивается в состоянии StateDone. Nothing означает, что входных данных не
осталось (мы обсудим это позднее). Она также выдает все полученные символы. Вторая
клауза просто добавляет символ к текущему состоянию и соощает, что мы продолжаем работу
в состоянии StateProcessing. Функция close возвращает все символы.

Функция sinkLines демонстрирует как мы можем использовать монадический интерфейс,
чтобы создавать новые sinks. Если вы замените sinkLine на getLine, это будет выглядеть
как обычный код, который забирает строки и стандартного входного потока. This familiar
interface should make it easy to get up and running quickly.
%FIXME

Типы

Типы для синков несколько более хитроумны, чем для источников. Давайте взглянем на них:

\begin{lstlisting}
type SinkPush input m output = input -> ResourceT m (SinkResult input m output)
type SinkClose m output = ResourceT m output

data SinkResult input m output =
    Processing (SinkPush input m output) (SinkClose m output)
  | Done (Maybe input) output

data Sink input m output =
    SinkNoData output
  | SinkData
        { sinkPush :: SinkPush input m output
        , sinkClose :: SinkClose m output
        }
  | SinkLift (ResourceT m (Sink input m output))
\end{lstlisting}  
% Whenever a sink is pushed to, it can either say it needs more data
% (Processing) or say it's all done. When still processing, it must provided
% updated push and close function; when done, it returns any leftover inut and the output.
% Fairly
% straight-forward.
% 
% The first real "gotcha" is the three constructors for Sink. Why do we need
% SinkNoData: aren't sinks all about consuming data? The answer is that we need
% it to efficiently implement our Monad instance. When we use
% return, we're giving back a value that requires no data in order to compute it.
% We could model this with the SinkData constructor, with something like:
% \begin{lstlisting}
% myReturn a = SinkData (\input -> return (Done (Just input) a)) (return a)
% \end{lstlisting}
% But doing so would force reading in an extra bit of input that we don't need right now,
% and
% possibly will never need. (Have a look again at the sinkLines example.) So
% instead, we have an extra constructor to indicate that no input is required. Likewise,
% SinkLift is provided in order to implement an efficient
% MonadTrans instance.
% 
% Sinks: no helpers
% Let's try to implement some sinks on the "bare metal", without any helper functions.
% \begin{lstlisting}
%   -- START
% import Data.Conduit
% import System.IO
% import Control.Monad.Trans.Resource
% import Control.Monad.IO.Class (liftIO)
% 
% -- Consume all input and discard it.
% sinkNull :: Resource m => Sink a m ()
% sinkNull =
%     SinkData push close
%   where
%     push _ignored = return $ Processing push close
%     close = return ()
% 
% -- Let's stream characters to a file. Here we do need some kind of
% -- initialization. We do this by initializing in a push function,
% -- and then returning a different push function for subsequent
% -- calls. By using withIO, we know that the handle will be closed even
% -- if there's an exception.
% sinkFile :: ResourceIO m => FilePath -> Sink Char m ()
% sinkFile fp =
%     SinkData pushInit closeInit
%   where
%     pushInit char = do
%         (releaseKey, handle) <- withIO (openFile fp WriteMode) hClose
%         push releaseKey handle char
%     closeInit = do
%         -- Never opened a file, so nothing to do here
%         return ()
% 
%     push releaseKey handle char = do
%         liftIO $ hPutChar handle char
%         return $ Processing (push releaseKey handle) (close releaseKey handle)
% 
%     close releaseKey _ = do
%         -- Close the file handle as soon as possible.
%         return ()
% 
% -- And we'll count how many values were in the stream.
% count :: Resource m => Sink a m Int
% count =
%     SinkData (push 0) (close 0)
%   where
%     push count _ignored =
%         return $ Processing (push count') (close count')
%       where
%         count' = count + 1
% 
%     close count = return count
% -- STOP
% main :: IO ()
% main = return ()
% \end{lstlisting}
% Nothing is particularly complicated to implement. You should notice a common pattern
here:
% declaring your push and close functions in a where clause, and then
% using them twice: once for the initial SinkData, and once for the
% Processing constructor. This can become a bit tedious; that's why
% we have helper functions.
% 
% Sinks: with helpers
% Let's rewrite sinkFile and count to take advantage of the
% helper functions sinkIO and sinkState, respectively.
% \begin{lstlisting}
%   -- START
% import Data.Conduit
% import System.IO
% import Control.Monad.IO.Class (liftIO)
% 
% -- We never have to touch the release key directly, sinkIO automatically
% -- releases our resource as soon as we return IODone from our push function,
% -- or sinkClose is called.
% sinkFile :: ResourceIO m => FilePath -> Sink Char m ()
% sinkFile fp = sinkIO
%     (openFile fp WriteMode)
%     hClose
%     -- push: notice that we are given the handle and the input
%     (\handle char -> do
%         liftIO $ hPutChar handle char
%         return IOProcessing)
%     -- close: we're also given the handle, but we don't use it
%     (\_handle -> return ())
% 
% -- And we'll count how many values were in the stream.
% count :: Resource m => Sink a m Int
% count = sinkState
%     0
%     -- The push function gets both the current state and the next input...
%     (\state _ignored -<
%         -- and it returns the new state
%         return $ StateProcessing $ state + 1)
%     -- The close function gets the final state and returns the output.
%     (\state -> return state)
% -- STOP
% main :: IO ()
% main = return ()
% \end{lstlisting}
% Nothing dramatic, just slightly shorter, less error-prone code. Using these two helper
% functions is highly recommended, as it ensures proper resource management and state
% updating.
%
Функции работы со списками

Можно легко писать собственные sinks, если вы пользуетесь встроенными примитивами из
модуля \verb*|Data.Conduit.List|. Там есть аналоги для типичных функций работы со
списками, например, свертки. (Там так же есть некоторые кондуиты,
например, conduit:Data.Conduit.List:map.)

Если вы желаете поупражняться в кондуитах, то реализация функций из модуля LIst (с
хэлперами и без) будет для начала неплохо.

Давайте сначала посмотрим на простые функции, которые можно подружить со встроенными
синками.
\begin{lstlisting}
-- START
import Data.Conduit
import qualified Data.Conduit.List as CL
import Control.Monad.IO.Class (liftIO)

-- A sum function.
sum' :: Resource m => Sink Int m Int
sum' = CL.fold (+) 0

-- Print every input value to standard output.
printer :: (Show a, ResourceIO m) => Sink a m ()
printer = CL.mapM_ (liftIO . print)

-- Sum up all the values in a stream after the first five.
sumSkipFive :: Resource m => Sink Int m Int
sumSkipFive = do
    CL.drop 5
    CL.fold (+) 0

-- Print each input number and sum the total
printSum :: ResourceIO m => Sink Int m Int
printSum = do
    total <- CL.foldM go 0
    liftIO $ putStrLn $ "Sum: " ++ show total
    return total
  where
    go accum int = do
        liftIO $ putStrLn $ "New input: " ++ show int
        return $ accum + int
-- STOP
main :: IO ()
main = return ()
\end{lstlisting}

Соединение

Наконец, мы хотим как-то поиспользовать наши синки. Пока мы умеет только вручную вызвать
\verb*|sinkPush| and \verb*|sinkClose|, но эт утомительно. Пример:
\begin{lstlisting}
import Data.Conduit
import Control.Monad.IO.Class (liftIO)

printSum :: Sink Int m Int
printSum = undefined
-- START
main :: IO ()
main = runResourceT $ do
    res <-
        case printSum of
            SinkData push close -> loop [1..10] push close
            SinkNoData res -> return res
    liftIO $ putStrLn $ "Got a result: " ++ show res
  where
    loop [] _push close = close
    loop (x:xs) push close = do
        mres <- push x
        case mres of
            Done _leftover res -> return res
            Processing push' close' -> loop xs push' close'
\end{lstlisting}
Вместо этого, рекомендуется соединять ваш синк с источником. Это проще, 
ошибок будет меньше, да и вас будет больше простора в том, откуда приходят ваши данные.
Перепишем пример выше:
\begin{lstlisting}
import Data.Conduit
import qualified Data.Conduit.List as CL
import Control.Monad.IO.Class (liftIO)

printSum :: Sink Int m Int
printSum = undefined
-- START
main :: IO ()
main = runResourceT $ do
    res <- CL.sourceList [1..10] $$ printSum
    liftIO $ putStrLn $ "Got a result: " ++ show res
\end{lstlisting}

Соединение требует проверки конструктора синка (SinkData vs. 
SinkNoData vs. SinkLift), запроса данных из источника , их передачи в синк и его закрытия.

Однако, есть один момент, который я хотел подчеркнуить таким длинным примером. Со второй
по последнюю строчки мы игнорируем значение, возвращаемое с Done. Это вносит проблему
потери данных. Это важная тема, которую стоило бы хорошенько обсудить. К сожалению,
сейчас мы не сможем полностью её осветить, так как мы не обсудили главного виновника
драмы: Conduits (the type, not the package). % FIXME добавить ссылку

Но если говорить кратко, то оставшееся значение не всегда игнорируется. Экземпляр Monad,
например, использует его для передачи данных из одной синки в другую по цепочке.
В действительности, настоящий оператор соединения не всегде отбрасывает остатки. Когда мы
обсудим источники, получение данных из которых можно приостанавливать (resumable), мы
увидим, что оставшееся значение складывается обратно в буфер, чтобы позволить последующим
синкам переиспользовать существующие источники для получения данных.

Кондуиты

В этой части мы рассмотрим главный тип данных в нашем пакете --- кондуиты. В то время как
источники генерируют данные а синки их поглощают, кондуиты преобразуют поток.

Типы

Также как мы и делали ранее, начнем с изучения используемых типов.
\begin{lstlisting}
data ConduitResult input m output =
    Producing (Conduit input m output) [output]
  | Finished (Maybe input) [output]

data Conduit input m output = Conduit
    { conduitPush :: input -> ResourceT m (ConduitResult input m output)
    , conduitClose :: ResourceT m [output]
    }
\end{lstlisting}
Это очень похоже на то, что мы видели с синками. В кондуит можно положить данные и в этом
случае он вернет результат. Этот результат демонстрирует либо, что данные ещё
генерируются, либо, что работа закончена. Если кондуит закрыт, то он возвращает некоторый
результат.


But let's examine the idiosyncracies a bit. Like sinks, we can only push one piece of
input at
a time, and leftover data may be 0 or 1 pieces. However, there are a few changes:

  
When producing (the equivalent of processing for a sink), we can return output. This is
because a conduit will product a new stream of output instead of producing a single
output
value
at the end of processing.
A sink always returns a single output value, while a conduit returns 0 or more outputs
(a
list). To understand why, consider conduits such as concatMap (produces
multiple outputs for one input) and filter (returns 0 or 1 output for each
input).
We have no special constructor like SinkNoData. That's because we provide no
Monad instance for conduits. We'll see later how you can still use a familiar
Monadic approach to creating conduits.
  
Overall conduits should seem very similar to what we've covered so far.

Простые кондуиты

Начнем с определения простейших кондуитов без состояния.
\begin{lstlisting}
  -- START
import Prelude hiding (map, concatMap)
import Data.Conduit

-- A simple conduit that just passes on the data as-is.
passThrough :: Monad m => Conduit input m input
passThrough = Conduit
    { conduitPush = \input -> return $ Producing passThrough [input]
    , conduitClose = return []
    }

-- map values in a stream
map :: Monad m => (input -> output) -> Conduit input m output
map f = Conduit
    { conduitPush = \input -> return $ Producing (map f) [f input]
    , conduitClose = return []
    }

-- map and concatenate
concatMap :: Monad m => (input -> [output]) -> Conduit input m output
concatMap f = Conduit
    { conduitPush = \input -> return $ Producing (concatMap f) $ f input
    , conduitClose = return []
    }
-- STOP
main :: IO ()
main = return ()
\end{lstlisting}
%  Stateful conduits
%   Of course, not all conduits can be declared without state. Doing so on the bare metal
is
% not
%    too difficult.
\begin{lstlisting}
  -- START
import Prelude hiding (reverse)
import qualified Data.List
import Data.Conduit
import Control.Monad.Trans.Resource

-- Reverse the elements in the stream. Note that this has the same downside as
-- the standard reverse function: you have to read the entire stream into
-- memory before producing any output.
reverse :: Resource m => Conduit input m input
reverse =
    mkConduit []
  where
    mkConduit state = Conduit (push state) (close state)
    push state input = return $ Producing (mkConduit $ input : state) []
    close state = return state

-- Same thing with sort: it will pull everything into memory
sort :: (Ord input, Resource m) => Conduit input m input
sort =
    mkConduit []
  where
    mkConduit state = Conduit (push state) (close state)
    push state input = return $ Producing (mkConduit $ input : state) []
    close state = return $ Data.List.sort state
-- STOP
main :: IO ()
main = return ()
\end{lstlisting} 
%  But we can do better. Just like sourceState and sinkState, we
%             have conduitState to simplify things.
% 
\begin{lstlisting}
  -- START
import Prelude hiding (reverse)
import qualified Data.List
import Data.Conduit

-- Reverse the elements in the stream. Note that this has the same downside as
-- the standard reverse function: you have to read the entire stream into
-- memory before producing any output.
reverse :: Resource m => Conduit input m input
reverse =
    conduitState [] push close
  where
    push state input = return $ StateProducing (input : state) []
    close state = return state

-- Same thing with sort: it will pull everything into memory
sort :: (Ord input, Resource m) => Conduit input m input
sort =
    conduitState [] push close
  where
    push state input = return $ StateProducing (input : state) []
    close state = return $ Data.List.sort state
-- STOP
main :: IO ()
main = return ()
\end{lstlisting}
% Using conduits
% 
% The way Conduits interact with the rest of the package is via
% fusing. A conduit can be fused into a source, producing a new source, fused into a
% sink to produce a new sink, or fused with another conduit to produce a new conduit. It's
% best to
% just look at the fusion operators.
\begin{lstlisting}
  -- Left fusion: source + conduit = source
($=) :: (Resource m, IsSource src) => src m a -> Conduit a m b -> Source m b

-- Right fusion: conduit + sink = sink
(=$) :: Resource m => Conduit a m b -> Sink b m c -> Sink a m c

-- Middle fusion: conduit + conduit = conduit
(=$=) :: Resource m => Conduit a m b -> Conduit b m c -> Conduit a m c
\end{lstlisting}
% Using these operators is straightforward.
\begin{lstlisting}
  useConduits = do
    runResourceT
          $  CL.sourceList [1..10]
          $= reverse
          $= CL.map show
          $$ CL.consume

    -- equivalent to
    runResourceT
          $  CL.sourceList [1..10]
          $$ reverse
          =$ CL.map show
          =$ CL.consume

    -- and equivalent to
    runResourceT
          $  CL.sourceList [1..10]
          $$ (reverse =$= CL.map show)
          =$ CL.consume
\end{lstlisting}
% There is in fact one last way of expressing the same idea. I'll leave it as an exercise
to
% the
% reader to discover it.
% 
% It may seem like all these different approaches are redundant. While occassionally you
can
% in
% fact choose whichever approach you feel like using, in many cases you will need a
specific
% approach. For example:
% 
%   
% If you have a stream of numbers, and you want to apply a conduit (e.g., map
% show) to only some of the stream that will be passed to a specific sink, you'll want
% to use the right fusion operator.
% If you're reading a file, and want to parse the entire file as textual data, you'll want
% to
% use left fusion to convert the entire stream.
% If you want to create reusable conduits that combine together individual, smaller
% conduits,
% you'll use middle fusion.
%   
% Data loss
% 
% Let's forget about conduits for a moment. Instead, suppose we want to write a program-
% using
% plain old lists- that will take a list of numbers, apply some kind of transformation to
% them,
% take the first five transformed values and do something with them, and then do something
% else
% with the remaining non-transformed values. For example, we want something like:
\begin{lstlisting}
  main = do
    let list = [1..10]
        transformed = map show list
        (begin, end) = splitAt 5 transformed
        untransformed = map read end
    mapM_ putStrLn begin
    print $ sum untransformed
\end{lstlisting}
% But clearly this isn't a good general solution, since we don't want to have to transform
% and
% then untransform every element in the list. For one thing, we may not always have an
% inverse
% function. Another issue is efficiency. In this case, we can write something more
% efficient:
\begin{lstlisting}
  main = do
    let list = [1..10]
        (begin, end) = splitAt 5 list
        transformed = map show begin
    mapM_ putStrLn transformed
    print $ sum end
\end{lstlisting}
% Note the change: we perform our split before transforming any elements. This works
% because,
% with map, we have a 1-to-1 correspondence between the input and output elements.
% So splitting at 5 before or after mapping show is the same thing. But what
% happens if we replace map show with something more devious.
\begin{lstlisting}
  deviousTransform =
    concatMap go
  where
    go 1 = [show 1]
    go 2 = [show 2, "two"]
    go 3 = replicate 5 "three"
    go x = [show x]
\end{lstlisting}
% We no longer have the 1-to-1 correspondence. As a result, we can't use the second
method.
% But
% it's even worse: we can't use the first method either, since there's no inverse of our
% deviousTransform.
% 
% There's only one solution to the problem that I'm aware of: transform elements one at a
% time.
% The final program looks like this:
\begin{lstlisting}
deviousTransform 1 = [show 1]
deviousTransform 2 = [show 2, "two"]
deviousTransform 3 = replicate 5 "three"
deviousTransform x = [show x]

transform5 :: [Int] -> ([String], [Int])
transform5 list =
    go [] list
  where
    go output (x:xs)
        | newLen <= 5 = (take 5 output', xs)
        | otherwise = go output' xs
      where
        output' = output ++ deviousTransform x
        newLen = length output'

    -- Degenerate case: not enough input to make 5 outputs
    go output [] = (output, [])

main = do
    let list = [1..10]
        (begin, end) = transform5 list
    mapM_ putStrLn begin
    print $ sum end
\end{lstlisting}    
%   The final output of this program is1
% 2
% two
% three
% three
% 49
% 
% What's important to note is that the number 3 is converted into five copies of the word
% "three", yet only two of
% them show up in the output. The rest are discarded in the take 5 call.
% 
% This whole exercise is just to demonstrate the issue of data loss in conduits. By
forcing
% conduits to accept only one input at a time, we avoid the issue of transforming too many
% elements
% at once. That doesn't mean we don't lose any data: if a conduit produces too much output
% for the receiving sink to handle, some of it may be lost.
% 
% To put all this another way: conduits avoid chunking to get away from data loss. This is
% not an
% issue unique to conduits. If you look in the implementation of concatMapM for
% enumerator, you'll see that it forces elements to be handled one at a time.
% In conduits, we opted to force the issue at the type level.
% 
% SequencedSink
% 
% Suppose we want to be able to combine up existing conduits and sinks to produce a new,
% more
% powerful conduit. For example, we want to write a conduit that takes a stream of numbers
% and sums
% up every five. In other words, for the input [1..50], it should result in the
% sequence [15,40,65,90,115,140,165,190,215,240]. We can definitely do this with
% the low-level conduit interface.
% \begin{lstlisting}
% import Data.Conduit
% -- START
% sum5Raw :: Resource m => Conduit Int m Int
% sum5Raw =
%     conduitState (0, 0) push close
%   where
%     push (total, count) input
%         | newCount == 5 = return $ StateProducing (0, 0) [newTotal]
%         | otherwise     = return $ StateProducing (newTotal, newCount) []
%       where
%         newTotal = total + input
%         newCount = count + 1
%     close (total, count)
%         | count == 0 = return []
%         | otherwise  = return [total]
% -- STOP
% main :: IO ()
% main = return ()
% \end{lstlisting}
% But this is frustrating, since we already have all the tools we need to do this at a
high
% level! There's the fold sink for adding up the numbers, and the
% isolate conduit which will only allow up to a certain number of elements to be
% passed to a sink. Can't we combine these somehow?
% 
% The answer is a SequencedSink. The idea is to create a normal
% Sink, except it returns a special output called a
% SequencedSinkResponse. This value can emit new output, stop processing data, or
% transfer control to a new conduit. (See the Haddocks for more information.) Then we can
% turn this
% into a Conduit using the sequenceSink function. This function
% also takes some state value that gets passed through to the sink.
% 
% So we can rewrite sum5Raw in a much more high-level manner.
% \begin{lstlisting}
% import Data.Conduit
% import qualified Data.Conduit.List as CL
% -- START
% sum5 :: Resource m => Conduit Int m Int
% sum5 = sequenceSink () $ \() -> do
%     nextSum <- CL.isolate 5 =$ CL.fold (+) 0
%     return $ Emit () [nextSum]
% -- STOP
% main = return ()
% \end{lstlisting}
% All of the () in there are simply the unused state variable being passed
% around, they can be ignored. Otherwise, we're doing exactly what we want. We fuse
% isolate to fold to get the sum of the next five elements from
% the stream. We then emit that value, and start all over again.
% 
% Let's say we want to modify this slightly. We want to get the first 8 sums, and then
pass
% through the remaining values, multiplied by 2. We can keep track of how many values
we've
% returned in our state, and then use the StartConduit constructor to pass control
% to the multiply-by-2 conduit next.
% \begin{lstlisting}
% import Data.Conduit
% import qualified Data.Conduit.List as CL
% -- START
% sum5Pass :: Resource m => Conduit Int m Int
% sum5Pass = sequenceSink 0 $ \count -> do
%     if count == 8
%         then return $ StartConduit $ CL.map (* 2)
%         else do
%             nextSum <- CL.isolate 5 =$ CL.fold (+) 0
%             return $ Emit (count + 1) [nextSum]
% -- STOP
% main = return ()
% \end{lstlisting}
% These are obviously very contrived examples, but I hope it makes clear the power and
% simplicity
% available from this approach.
% 
Buffering

Buffering is one of the unique features of conduits. With buffering, conduits no longer
need to
control the flow of your application. In some cases, this can lead to simpler code.

Inversion of Control

Buffering was actually one of the main motivations in the creation of the
conduit package. To see its importance, we need to consider the approach we've
seen so far, which we'll call inversion of control, or IoC.

Inversion of control can mean different things in different circles. If you object to its
usage here, go ahead replace it with some other phrase like "warm, fuzzy thing." I won't
be
offended.

Suppose you want to count how many newline characters there are in a file. In the standard
imperative approach, you would do someting like:

  
   Open the file
   Pull some data into a buffer
   Loop over the values in the buffer, incrementing a counter on each newline character
   Return to 2
   Close the file
  
Notice that your code is explicitly calling out to other code and that code is returning
control back to your code. You have retained full control of the flow of execution of your
program. The conduit approach we've seen so far does not work this way. Instead, you
would:
  
Write a sink that counts newlines and adds the result to an accumulator.
Connect the sink to a source
  
There's no doubt in my mind that this is an easier approach. You don't have to worry about
opening and closing files or pulling data from the file. Instead, the data you need to
process is
simply presented to you. This is the advantage of IoC: you can focus on specifically your
piece
of the code.

We use this IoC approach all over Haskell: for example, instead of readMVar
and putMVar, you can use withMVar. Don't bother with
openFile and closeFile, just use withFile and
pass in a function that uses the Handle. Even C has a version of this: why
malloc and free when you could just alloca?

Actually, that last one is a huge red herring. Of course you can't just use
alloca for everything. alloca only allocates memory locally on
the stack, not dynamically on the heap. There's no way to return your allocated memory
outside
the current function.

But actually, the same restriction applies to the whole family of with
functions: you can never return an allocated resource outside of the "block". Usually this
works
out just fine, but we need to recognize that this is a change in how we structure our
programs. Often times, with simple examples, this is a minor change. However, in larger
settings
this can become very difficult to manage, bordering on impossible at times.

A web server

Let's say we're going to write a web server. We're going to use the following low-level
operations:
\begin{lstlisting}
data Socket
recv    :: Socket -> Int -> IO ByteString -- returns empty when the socket is closed
sendAll :: Socket -> ByteString -> IO ()
\end{lstlisting}
We're up to the part where we need to implement the function handleConn that
handles an individual connection. It will look something like this:
\begin{lstlisting}
data Request  -- request headers, HTTP version, etc
data Response -- status code, response headers, resposne body
type Application = Request -> IO Response
handleConn :: Application -> Socket -> IO ()
\end{lstlisting}
What does our handleConn need to do? In broad strokes:

  
   Parse the request line
   Parse the request headers
   Construct the Request value
   Pass Request to the Application and get back a Response
   Send the Response over the Socket
  
We start off by writing steps 1 and 2 manually, without using conduits. We'll do this very
simply and just assume three space-separated strings. We end up with something that looks
like:
\begin{lstlisting}
data RequestLine = RequestLine ByteString ByteString ByteString

parseRequestLine :: Socket -> IO RequestLine
parseRequestLine socket = do
    bs <- recv socket 4096
    let (method:path:version:ignored) = S8.words bs
    return $ RequestLine method path version
\end{lstlisting}
There are two issues here: it doesn't handle the case where there are less than three
words in
the chunk of data, and it throws away any extra data. We can definitely solve both of
these
issues manually, but it's very tedious. It's much easier to implement this in terms of
conduits.
\begin{lstlisting}
-- START
import Data.ByteString (ByteString)
import qualified Data.ByteString as S
import Data.Conduit
import qualified Data.Conduit.Binary as CB
import qualified Data.Conduit.List as CL

data RequestLine = RequestLine ByteString ByteString ByteString

parseRequestLine :: Sink ByteString IO RequestLine
parseRequestLine = do
    let space = toEnum $ fromEnum ' '
    let getWord = do
            CB.dropWhile (== space)
            bss <- CB.takeWhile (/= space) =$ CL.consume
            return $ S.concat bss

    method <- getWord
    path <- getWord
    version <- getWord
    return $ RequestLine method path version
-- STOP
main = return ()
\end{lstlisting}
This means that our code will automatically be supplied with more data as it comes in, and
any
extra data will automatically be buffered in the Source, ready for the next time
it's used. Now we can easily structure our program together, demonstrating the power of
the
conduits approach:
\begin{lstlisting}
  -- START
import Data.ByteString (ByteString)
import Data.Conduit
import Data.Conduit.Network (sourceSocket)
import Control.Monad.IO.Class (liftIO)
import Network.Socket (Socket)

data RequestLine = RequestLine ByteString ByteString ByteString
type Headers = [(ByteString, ByteString)]
data Request = Request RequestLine Headers
data Response = Response
type Application = Request -> IO Response

parseRequestHeaders :: Sink ByteString IO Headers
parseRequestHeaders = undefined

parseRequestLine :: Sink ByteString IO RequestLine
parseRequestLine = undefined

sendResponse :: Socket -> Response -> IO ()
sendResponse = undefined

handleConn :: Application -> Socket -> IO ()
handleConn app socket = do
    req <- runResourceT $ sourceSocket socket $$ do
        requestLine <- parseRequestLine
        headers <- parseRequestHeaders
        return $ Request requestLine headers
    res <- liftIO $ app req
    liftIO $ sendResponse socket res
-- STOP
main = return ()
\end{lstlisting}
Whither the request body?
This is all great, until we realize we can't read the request body. The
Application is simply given the Request, and lives in the
IO monad. It has no access whatsoever to the incoming stream of data.

There's an easy fix for this actually: have the Application live in the
Sink monad. This is the very approach we took with
enumerator-based WAI 0.4. However, there are two problems:


People find it confusing. What people expect is that the Request
value would have a requestBody value of type Source.
This makes certain kinds of usage incredibly difficult. For example, trying to write an
HTTP
proxy combining WAI and http-enumerator proved to be almost impossible.

This is the downside of inversion of control. Our code wants to be in control. It wants to
be
given something to pull from, something to push to, and run with it. We need some solution
to the
problem.

If you think that the situation I described with the proxy isn't so bad, it's because I've
gone easy on the details. We also need to take into account streaming the response body,
and the
streaming needs to happen on both the client and server side.
The simplest solution would be to just create a new Source and pass that to
the Application. Unfortunately, this will cause problems with our buffering. You
see, when we connect our source to the parseRequestLine and
parseRequestHeaders sinks, it made a call to recv. If the data
it received was not enough to cover all of the headers, it would issue another call. When
it had
enough data, it would stop. However, odds are that it didn't stop exactly at the end of
the headers. It likely consumed a bit of the request body as well.

If we just create a new source and pass that to the request, it will be missing the
beginning
of the request body. We need some way to pass that buffered data along.

BufferedSource

And so we finally get to introduce the last data type in conduits:
BufferedSource. This is an abstract data type, but all it really does is keep a
mutable reference to a buffer and an underlying Source. In order to create one
of these, you use the bufferSource function.

bufferSource ::Resource m =< Source m a -< ResourceT m (BufferedSource m a)
This one little change is what allows us to easily solve our web server dilemna. Instead
of
connecting a Source to our parsing Sinks, we use a
BufferedSource. At the end of each connection, any leftover data is put back on
the buffer. For our web server case, we can now create a BufferedSource, use
that to read the request line and headers, and then pass that same
BufferedSource to the application for reading the request body.

Typeclass

We want to be able to connect a buffered source to a sink, just like we would a regular
source.
We would also like to be able to fuse it to a conduit. In order to make this convenient,
conduit
has a typeclass, IsSource. There are instances provided for both
Source and BufferedSource. Both the connect
(\verb#$$#) and left-fuse (\verb#$=#) operators use this typeclass.

There's one "gotcha" in the BufferedSource instance of this typeclass, so
let's explain it. Suppose we want to write a file copy function, without any buffering.
This is a
fairly standard usage of conduits:
\begin{lstlisting}
sourceFile input $$ sinkFile output
\end{lstlisting}
When this line is run, both the input and output files are opened, the data is copied, and
then
both files are closed. Let's change this example slightly to use buffering:
\begin{lstlisting}
bsrc <- bufferSource $ sourceFile input
bsrc $$ isolate 50 =$ sinkFile output1
bsrc $$ sinkFile output2
\end{lstlisting}
When is the input file opened and closed? The opening occurs on the first line, when
buffering
the source. And if we follow the normal rules from sources, the file should be closed
after the
second line. However, if we did that, we couldn't reuse bsrc for line 3!

So instead, \verb#$$# does not close the file. As a result, you can pass a
buffered source to as many actions as you want, without concerns that the file handle has
been
closed out from under you.

If you remember from earlier, the invariant of a source is that it cannot be pulled from
after it returns a Closed response. In order to allow you to work more easily
with a BufferedSource, this invariant is relaxed. It is the responsibility of
the BufferSource implementation to ensure that after the underlying
Source is closed, it is never used again.
This presents one caveat: when you're finished with a buffered source, you should manually
call
bsourceClose on it. However, as usual, this is merely an optimization, as the
source will automatically be closed when runResourceT is called.

Recapping the web server
So what exactly does our web server look like now?
\begin{lstlisting}
  -- START
import Data.ByteString (ByteString)
import Data.Conduit
import Data.Conduit.Network (sourceSocket)
import Control.Monad.IO.Class (liftIO)
import Network.Socket (Socket)

data RequestLine = RequestLine ByteString ByteString ByteString
type Headers = [(ByteString, ByteString)]
data Request = Request RequestLine Headers (BufferedSource IO ByteString)
data Response = Response
type Application = Request -> ResourceT IO Response

parseRequestHeaders :: Sink ByteString IO Headers
parseRequestHeaders = undefined

parseRequestLine :: Sink ByteString IO RequestLine
parseRequestLine = undefined

sendResponse :: Socket -> Response -> IO ()
sendResponse = undefined

handleConn :: Application -> Socket -> IO ()
handleConn app socket = runResourceT $ do
    bsrc <- bufferSource $ sourceSocket socket
    requestLine <- bsrc $$ parseRequestLine
    headers <- bsrc $$ parseRequestHeaders
    let req = Request requestLine headers bsrc
    res <- app req
    liftIO $ sendResponse socket res
-- STOP
main = return ()
\end{lstlisting}
We've made a few minor changes. Firstly, the Application now lives in the
ResourceT IO monad. This isn't strictly necessary, but it's very convenient:
the application can now register cleanup actions that will only take place after the
response has
been fully sent to the client.

But the major changes are in the handleConn function. We now start off by
buffering our source. This buffered source is then used twice in our function, and then
passed
off to the application.


